# This file was auto-generated by Fern from our API Definition.

from ....core.pydantic_utilities import UniversalBaseModel
import pydantic
import typing
import datetime as dt
from .model_usage_unit import ModelUsageUnit
from ....core.pydantic_utilities import IS_PYDANTIC_V2


class Model(UniversalBaseModel):
    """Model definition used for transforming usage into USD cost and/or tokenization.
    """

    id: str
    model_name: str = pydantic.Field(alias="modelName")
    """
    Name of the model definition. If multiple with the same name exist, they are applied in the following order: (1) custom over built-in, (2) newest according to startTime where model.startTime<observation.startTime
    """

    match_pattern: str = pydantic.Field(alias="matchPattern")
    """
    Regex pattern which matches this model definition to generation.model. Useful in case of fine-tuned models. If you want to exact match, use `(?i)^modelname$`
    """

    start_date: typing.Optional[dt.date] = pydantic.Field(
        alias="startDate", default=None
    )
    """
    Apply only to generations which are newer than this ISO date.
    """

    unit: ModelUsageUnit = pydantic.Field()
    """
    Unit used by this model.
    """

    input_price: typing.Optional[float] = pydantic.Field(
        alias="inputPrice", default=None
    )
    """
    Price (USD) per input unit
    """

    output_price: typing.Optional[float] = pydantic.Field(
        alias="outputPrice", default=None
    )
    """
    Price (USD) per output unit
    """

    total_price: typing.Optional[float] = pydantic.Field(
        alias="totalPrice", default=None
    )
    """
    Price (USD) per total unit. Cannot be set if input or output price is set.
    """

    tokenizer_id: typing.Optional[str] = pydantic.Field(
        alias="tokenizerId", default=None
    )
    """
    Optional. Tokenizer to be applied to observations which match to this model. See docs for more details.
    """

    tokenizer_config: typing.Optional[typing.Optional[typing.Any]] = pydantic.Field(
        alias="tokenizerConfig", default=None
    )
    """
    Optional. Configuration for the selected tokenizer. Needs to be JSON. See docs for more details.
    """

    is_langfuse_managed: bool = pydantic.Field(alias="isLangfuseManaged")

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(
            extra="allow", frozen=True
        )  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
